---
title: 笔记：操作系统理论
date: 2025-06-03
categories:
  - 操作系统
  - 操作系统理论
tags: 
author: 霸天
layout: post
---
1. 操作系统的特征
	1. 并发、共享、异步、虚拟
2. 操作系统的功能
	1. 处理器管理、存储器管理、文件管理、设备管理
3. 进程的特性
	1. 动态、并发、独立、异步、结构
4. 死锁产生的原因
	1. 系统资源的竞争、进程推进顺序非法
5. 死锁产生的必要条件
	1. 互斥、不剥夺、请求并保持、循环等待
6. 解除死锁
7. 进程的定义
	1. 进程（Process），是计算机中的程序关于某个数据集合的一次运行活动，是系统进行 **资源分配和调度** 的一个基本单位，我们简单理解为：一个进程就是一个程序在操作系统中实际运行时的一个实例
8. 死锁的定义
	1. 死锁是指多个进程因竞争资源而相互等待，导致彼此陷入阻塞状态，若无外力干预，这些进程将永远无法继续执行。
9. 内存分区分配的时候，四种适应算法的优缺点
	1. 首次适应
		1. 实现简单，查找效率较高，从头开始搜索空闲分区链表，一旦找到足够大的空间就分配
		2. 可能导致低地址空间碎片化，因为这里会留下很多小的、不可用的分区；分配速度虽然快，但可能导致后续的分配需要遍历更长的列表
	2. 最佳适应
		1. 尝试找到最接近所需大小的分区进行分配，理论上可以最大化地利用内存
		2. 需要遍历整个空闲分区列表来寻找最佳匹配，这增加了分配时间；容易产生大量非常小的难以再利用的碎片
	3. 最坏适应
		1. 总是选择最大空闲分区进行分配，尽可能留下大的剩余空间，便于后续大进程的分配
		2. 实际上可能造成大的空闲块被分割成多个中等大小的碎片，浪费空间；而且需要遍历整个空闲表，查找效率较低
	4. 临近适应
		1. 与首次适应类似，但从上一次分配结束的位置继续向后查找，提高了遍历效率，避免总从头开始搜索
		2. 在空闲分区不均匀分布时可能会跳过合适区域，导致整体内存利用率下降；
10. 内存的分配方式有，分别怎么储存信息
	1. 单一连续分配
	2. 固定分区分配
	3. 动态分区分配
	4. 分页
	5. 分段
	6. 段页
11. 处理机的调度方式
	1. 先来先服务
	2. 短作业优先
	3. 高响应比优先
	4. 时间片轮转
12. 文件分配方式
	1. 连接
	2. 链接
	3. 索引
13. FCB 是什么，作用是什么
	1. FCB 是操作系统为每一个文件维护的**结构化信息集合**，用于记录文件的各种属性与存储信息。
	2. FCB 是文件系统中**连接“用户”和“磁盘数据”之间的桥梁**。其主要作用包括：
		1. 描述文件属性
		2. 指示文件位置
		3. 支持文件访问控制
		4. 支持文件读写操作
		5. 管理文件状态
14. 简述设备按传输速率分类的三种主要类型及其特点
15. 
























## 1. 导图：[Map：操作系统](Map：操作系统.xmind)

---


 ## 2. 操作系统

### 2.1. 操作系统概述

操作系统（OS）是一类系统**软件**，负责管理计算机的硬件资源、协调应用程序的执行，并为用户提供操作界面，其主要实现了以下功能：
1. ==进程管理==：
	1. 负责进程的生命周期管理与协调，确保多任务环境下的高效运行。
	2. 主要包括：
		1. 进程的创建、终止、挂起与恢复
		2. 进程间的同步与通信机制（如信号量、管道、消息队列）
		3. 进程状态管理与切换（如就绪、运行、阻塞）
		4. 死锁的预防与检测
2. ==处理机管理（CPU 管理）==：
	1. 专注于 CPU 资源的分配与调度，在操作系统课程中，通常作为进程管理的子模块
	2. 主要包括：
		1. 处理机调度策略（如先来先服务、优先级调度、时间片轮转等）
		2. 中断处理与上下文切换，确保 CPU 高效利用
3. ==存储器管理（内存管理）==：
	1. 高效、安全地管理系统内存，满足程序运行时的内存需求并确保进程隔离
	2. 主要包括：
		1. 内存的动态分配与回收（如堆管理、内存池）
		2. 地址映射与转换（如逻辑地址到物理地址的转换）
		3. 内存保护与共享机制（如页面保护、段共享）
		4. 虚拟内存实现（如分页、页面置换算法）
4. ==文件管理==：
	1. 将底层存储设备组织为逻辑文件系统，便于数据的存储、访问与管理
	2. 主要包括：
		1. 文件存储空间的分配与回收（如空闲块管理）
		2. 目录结构的管理与文件路径解析
		3. 文件的读写控制与访问权限管理（如ACL、权限位）
		4. 文件系统的可靠性与性能优化（如日志、缓存）
5. ==设备管理==：
	1. 协调多种外部设备的使用，提升输入/输出（I/O）操作的效率与并发性
	2. 主要包括：
		1. I/O 缓冲区管理，减少设备访问延迟
		2. 设备的分配、调度与回收（如设备驱动程序）
		3. 设备请求的处理与中断机制
		4. 虚拟设备支持（如虚拟磁盘、虚拟终端）
6. ==网络管理==：
	1. 管理网络通信，支持计算机之间的数据交换与资源共享
	2. 主要包括：
		1. 网络协议栈的实现与管理（如TCP/IP）
		2. 网络连接的建立、维护与断开
		3. 网络安全与访问控制（如防火墙、加密）
		4. 分布式系统的资源共享与通信
7. ==提供用户接口==：
	1. 提供用户与计算机交互的接口，便于操作与控制
	2. 主要包括：
		1. 命令行界面（CLI），如 Shell 终端
		2. 图形用户界面（GUI），如Windows、GNOME
		3. 其他交互方式，如触摸界面或语音控制
![](source/_posts/笔记：操作系统理论/image-20250603111913745.png)

> [!NOTE] 注意事项
> 1. 不要把操作系统仅仅看作是对硬件的管理者，它管理的是计算机资源。
> 2. 凡是你在计算机中能叫出名字的资源，无论是硬件设备、内存空间、文件、进程，还是各种逻辑资源，基本都在操作系统的管理范围之内。

---


## 3. 进程管理

### 3.1. 进程概述

进程（Process），是计算机中的程序关于某个数据集合的一次运行活动，是系统进行 **资源分配和调度** 的一个基本单位，我们简单理解为：一个进程就是一个程序在操作系统中实际运行时的一个实例

在早期的分时系统中，进程是操作系统进行任务调度和执行的基本单位。然而，在现代操作系统中，我们引入了线程（Thread）的概念，进程不再是基本的执行单位，而是作为**线程的容器**存在，真正被调度和执行的单元变成了线程。

---


### 3.2. 进程的状态

![](source/_posts/笔记：操作系统理论/image-20250604120226825.png)
1. ==创建状态==：
	1. 当用户或系统请求创建一个新进程时，操作系统会为其分配必要的资源，例如在内核中创建进程控制块（PCB）、将装入程序加载到内存等
2. ==就绪状态==：
	1. <font color="#7030a0">活动就绪</font>：
		1. 进程已完成创建，并具备所有执行条件（如所需的内存、资源、I/O 等），可以随时被 CPU 调度
		2. 此时进程驻留在内存中，进入“活动就绪队列”（也称为就绪队列），等待 CPU 调度
	2. <font color="#7030a0">静止就绪</font>：
		1. 当高优先级进程或系统内存压力较大时，部分活动就绪进程可能被踢出主存，转存至二级存储（如交换区/swap 空间或后备存储）
		2. 这类进程虽然不再占用主存，但其状态仍为“就绪”，即一旦被换入内存并获得 CPU 调度，即可立即运行
		3. 操作系统通常将其放入“静止就绪队列”（该队列本身位于内存中），等待后续的换入操作
3. ==运行状态==：
	1. 调度器从 “活动就绪队列” 中根据调度算法选择一个进程，将其上下文加载至 CPU 寄存器，并设置相应页表，使其进入 “运行” 状态
	2. 在该状态下，进程独占一个处理器核心（一个核只能处理一个指令流，假设进程为单指令流，即单线程）
4. ==阻塞状态==：
	1. <font color="#7030a0">活动阻塞</font>：
		1. 进程在运行过程中由于某些条件未满足（如等待 I/O 完成或资源释放）而无法继续执行，此时将其移出 CPU 并置于阻塞队列中，状态变为“活动阻塞”
		2. 进程仍驻留在内存中，等待所依赖事件完成后再转为就绪状态
		3. **不是说一个线程，一直等待莫，咋不一样还能被移除 CPU？算了到时候在管**
	2. <font color="#7030a0">静止阻塞</font>：
		1. 即通常所说的进程挂起。处于“活动阻塞”状态的进程，如果长时间无法继续执行，且系统内存紧张，可能会被操作系统换出（swapping out）到磁盘或其他后备存储，即使其所等待的 I/O 或事件尚未完成，也会优先将其从主存中移除，以释放内存资源供其他进程使用
		2. 此时进程既不占用 CPU，也不占用主存，仍处于“等待事件”的状态。当该进程被换回内存后，才有可能继续运行
5. ==终止状态==：
	1. 当进程正常结束或发生异常退出时，会被标记为“终止”，随后操作系统将回收其占用的所有资源，包括内存空间、打开的文件、内核对象等

----


### 3.3. 进程通信

---


### 3.4. 进程同步

#### 3.4.1. 进程同步概述

进程同步并不是日常所说的数据同步，而是指在并发执行时，多个进程之间通过相互制约，按照特定顺序协同执行的过程，它依赖于两种不同的相互制约形式：
1. ==间接相互制约关系（互斥）==：
	1. 指进程排他性地访问共享资源
	2. 典型场景如：多个进程不能同时访问同一段临界区，例如对同一个文件进行写操作
2. ==直接相互制约关系（同步）==：
	1. 指多个进程之间需要协作，按一定顺序完成任务
	2. 比如一个进程负责写数据，另一个进程负责读数据，必须先写后读——这类典型例子就是管道通信、生产者-消费者问题

----

#### 3.4.2. 间接相互制约关系（互斥）

##### 3.4.2.1. 临界资源的访问过程

![](source/_posts/笔记：操作系统理论/image-20250605185358630.png)

> [!NOTE] 注意事项
> 1. 唤醒处于阻塞状态的进程时，可以选择只唤醒一个，也可以同时唤醒多个
> 2. 那些阻塞进程会先来后到的进入阻塞队列

----


##### 3.4.2.2. 临界资源的访问原则

临界资源的访问原则包括：
1. ==空闲让进==：
	1. 当临界区空闲时，允许一个进程立即进入
2. ==忙则等待==：
	1. 当已有进程在临界区内，其他进程必须等待（进入阻塞状态）
3. ==有限等待==：
	1. 任何一个请求访问临界区的进程，其等待时间应是有限的，避免饥饿现象
4. ==让权等待==：
	1. 当进程无法进入临界区时，应主动让出 CPU 的执行权，避免因持续占用 CPU 而产生“忙等待”，造成资源浪费
	2. 这也是为什么在进程阻塞时，CPU 会转而去调度执行其他就绪进程，以提高系统整体效率
    
-----


##### 3.4.2.3. 临界互斥的软件方法（基本方法）

###### 3.4.2.3.1. 单标志法

###### 3.4.2.3.2. 双标志法先检查


###### 3.4.2.3.3. 双标志法后检查


###### 3.4.2.3.4. 皮特森算法

---


##### 3.4.2.4. 临界互斥的硬件方法（基本方法）


---


##### 3.4.2.5. 信号量（临界互斥的高级方法）

###### 3.4.2.5.1. 信号量概述

信号量是实现临界互斥的高级方法，是我们大名鼎鼎的 唤醒---等待操作，主要有：
1. 整型信号量
2. 记录型信号量

----


###### 3.4.2.5.2. 整形信号量

缺点是是 CPU 忙等
![](source/_posts/笔记：操作系统理论/image-20250605192232877.png)

---


###### 3.4.2.5.3. 记录型信号量

解决 CPU 忙等问题
![](source/_posts/笔记：操作系统理论/image-20250605191804066.png)

---


#### 3.4.3. 死锁

##### 3.4.3.1. 死锁概述

死锁是指多个进程因竞争资源而相互等待，导致彼此陷入阻塞状态，若无外力干预，这些进程将永远无法继续执行。

> [!NOTE] 注意事项
> 1. 与此类似的概念是饥饿：指进程长时间得不到所需资源，虽然还能继续推进，但响应和进度受到明显影响，呈现“饿而不死”的状态。

----


##### 3.4.3.2. 死锁产生的原因

死锁产生的原因有：
1. 系统资源的竞争
2. 进程推进顺序非法

---


##### 3.4.3.3. 死锁产生的必要条件

![](source/_posts/笔记：操作系统理论/image-20250605203459668.png)

---


##### 3.4.3.4. 死锁的预防

==1.破坏互斥条件==
![](source/_posts/笔记：操作系统理论/image-20250605203754645.png)


==2.破坏不可剥夺条件==
![](source/_posts/笔记：操作系统理论/image-20250605204107933.png)


==3.破坏请求并保持条件==
![](source/_posts/笔记：操作系统理论/image-20250605204157303.png)


==4.破坏循环等待条件==
![](source/_posts/笔记：操作系统理论/image-20250605204314508.png)

---


##### 3.4.3.5. 死锁的避免


也就是我们大名鼎鼎的银行家算法，进程需要在开始时向操作系统声明其**最大可能资源需求**，以图中的 P0 为例，声明的最大需求为 10 个资源，当前已分配了 5 个。

现在 P0 向操作系统申请 6 个资源，OS 一计算：你这次要 6 个，加上已有的 5 个，总共就是 11 个，已经超过了你最初声明的最大需求 —— 操作系统据此预判此请求**可能导致系统进入不安全状态**（即可能引发死锁），于是**拒绝请求**。

如果 P0 这次只申请 5 个资源，虽然总需求没有超过最大值，但操作系统检查当前**可用资源数为 3 个**，仍无法满足请求，因此也会**拒绝分配**。
![](source/_posts/笔记：操作系统理论/image-20250605205200815.png)

----


##### 3.4.3.6. 死锁的检测

###### 3.4.3.6.1. 死锁的检测概述

即便我们有了死锁的预防和死锁的避免机制，也不能保证系统就绝对不会发生死锁。比如在程序运行过程中，可能会人为动态地创建线程或进程，这些行为是操作系统事先无法完全预测的，而新的资源请求也可能引发死锁。

那么一旦死锁真的发生了，我们该如何检测？其实方法就是：绘制资源分配图，然后根据死锁定理来判断当前是否存在死锁。

---

###### 3.4.3.6.2. 资源分配图

![](source/_posts/笔记：操作系统理论/image-20250605210113393.png)

----


###### 3.4.3.6.3. 资源分配图的简化

资源分配图的简化就是去找那些不是孤点（即存在分配边或请求边）、不处于阻塞状态（即其请求的资源当前可满足）的点。

如上图所示：  R1 为 P0 分配了 2 个资源，为 P1 分配了 1 个资源，此时 R1 中没有剩余资源；  R2 为 P1 分配了 1 个资源，当前仍剩下 1 个资源。

我们先看 P0：P0 正在向 R2 请求一个资源，而 R2 中还有资源可用，说明 P0 能够获取资源，满足条件；  
然后再看 P1：P1 正在向 R1 请求资源，但 R1 当前没有可用资源，不满足条件，处于阻塞状态。

因此，我们将满足条件的 P0 的所有请求边和分配边从图中删除，如下图所示：
![](source/_posts/笔记：操作系统理论/image-20250605211455385.png)

随后，P0 执行完成并归还其占用的所有资源。这时 R1 中恢复了两个资源。我们再次观察 P1：此时它请求 R1 的资源，而 R1 已有空闲资源，因此 P1 现在满足条件。于是我们也将 P1 的出边和入边删除，如下图所示：
![](source/_posts/笔记：操作系统理论/image-20250605211635746.png)

所以这是一个完全简化过程，说明此状态下不存在死锁，对应的进程执行顺序可以表示为：P0 → P1

> [!NOTE] 注意事项
> 1. 如果最终资源分配图无法被完全简化——也就是说，还有一部分进程和资源残留在图中，始终找不到能继续推进的进程，这就叫做不完全简化。

---


###### 3.4.3.6.4. 死锁定理

死锁定理是判定系统是否已发生死锁的充分条件。一旦触发死锁定理，即说明系统中确实存在死锁。

该定理的内容是：当且仅当资源分配图在当前状态下**不可完全简化**时，系统已进入死锁状态。

> [!NOTE] 注意事项
> 1. 这里的“简化过程”类似于“拓扑排序”的方式

---


##### 3.4.3.7. 死锁的解除

死锁的解除通常有以下几个方式：
1. ==资源剥夺==：
	1. 挂起死锁进程
	2. 剥夺其资源
	3. 将资源分配给其他死锁进程
2. ==撤销进程==
3. ==进程回退==：
	1. 回退到足以避免死锁的地步
	2. 这个方式需要记录进程的历史信息，设置还原点

---


## 4. 处理机管理

### 4.1. 处理机调度

#### 4.1.1. 处理机调度概述

处理器调度是指：操作系统从 **就绪队列** 中选择一个进程，并将某一个核心的 CPU 控制权分配给该进程，以执行其指令的过程。

> [!NOTE] 注意事项
> 1. 在任意时刻，一个处理器核心只能执行一条指令流，该指令流可能来自一个单线程进程，也可能是某个多线程进程中的一个线程
> 2. 因为早期多数应用为单线程进程应用，因此 “将 CPU 控制权分配给进程” 这一说法通常默认该进程只包含一个线程。毕竟，一个核心在任一时刻只能执行一个指令流。

---


#### 4.1.2. 处理机调度的层次

1. ==高级调度（作业调度）==：
	1. 负责从外存（硬盘）中选择作业（程序）加载到内存中创建成进程的过程
2. ==中级调度（内存对换）==：
	1. 控制在内存中运行的进程数量，把暂时不用的进程换出到磁盘，条件合适再调入内存（也就是进程挂起）
3. ==低级调度（进程调度）==：
	1. 从就绪队列中选择一个进程把 CPU 分给它，这就是我们平时说的 “调度算法” 的核心所在

下图是高级调度（作业调度）的示意图：
![](source/_posts/笔记：操作系统理论/image-20250605155209835.png)

---


#### 4.1.3. 处理机调度的方式

1. ==剥夺式调度（抢占式调度）==：
	1. 一个进程运行中可能会被强行中断（如被更高优先级的抢占、时间片用完等）
2. ==非剥夺式调度（非抢占式调度）==：
	1. 进程一旦获得 CPU，就会运行到它主动放弃为止（如运行结束或进入阻塞状态），适用于批处理系统，不适用于分时 / 实时 系统

> [!NOTE] 注意事项
> 1. 再非剥夺式调度下，即便进程时间片用完，也一直会运行下去，直到它主动释放 CPU

---


#### 4.1.4. 处理机调度的时机（触发条件）

处理机调度的常见时机有：
1. 进程运行完毕
2. 进程时间片用完
3. 进程要求 I/O 操作（进入阻塞状态）
4. 执行某种原语操作
5. 高优先级进程申请运行

> [!NOTE] 注意事项
> 1. 到底是否会触发调度，取决于处理机的调度策略。例如：在剥夺式调度中，进程时间片用完后可以被调度，而在非剥夺式调度中则不会；高优先级进程请求运行时，是否能立即调度同样取决于调度方式。

---


#### 4.1.5. 处理机调度的过程（进程调度）

处理机调度的过程大致为：
1. ==保存当前进程状态==：
	1. 如果当前有进程正在运行，而调度器决定换出它（即不是因为它自己退出），则需要先保存它的运行状态到该进程的 PCB（进程控制块）中
	2. 这是为了确保未来该进程还能从断点位置继续执行
2. ==选择新进程==：
	1. 调度器根据调度算法（如FCFS、SJF、优先级、轮转等）从就绪队列中挑选一个合适的进程
	2. 一旦选中合适的进程，调度器会更新该进程的状态（就绪 -> 运行）
3. ==恢复新进程状态==：
	1. 系统准备让新进程运行，需要恢复它原先保存的状态，即从 PCB 中读取数据加载到 CPU 中
4. ==跳转执行新进程==：
	1. 操作系统将 CPU 控制权交给新进程，CPU 从新进程的程序计数器指示的位置继续执行，直到下一次调度

---
   

#### 4.1.6. 处理机调度的评价指标

1. ==CPU 利用率（越高越好）==：
    1. CPU 利用率 = CPU 忙碌时间 / 总时间
2. ==系统吞吐量（越高越好）==：
    1. 表示单位时间内系统完成的作业数量
    2. 系统吞吐量 = 完成的作业数 / 总时间
3. ==周转时间（越低越好）==：
    - 指作业从提交到完成所经历的总时间
    - 周转时间 = 完成时间 - 提交时间
4. ==带权周转时间（越低越好）==：
    - 用于衡量作业被延迟的程度，相对考虑运行时间
    - 带权周转时间 = 周转时间 / 实际运行时间
5. ==等待时间（越低越好）==：
    - 指作业在就绪队列中等待调度运行的总时间
    - 通常是周转时间 - 实际运行时间 - I/O 等待时间（如有）
6. ==响应时间（越低越好）==：
    - 指用户提交请求到系统首次产生响应的时间间隔
    - 尤其关键于交互式系统和实时系统

---


#### 4.1.7. 处理机调度的常见算法

##### 4.1.7.1. 处理机调度的常见算法概述

![](source/_posts/笔记：操作系统理论/image-20250605164732952.png)

> [!NOTE] 注意事项
> 1. 不要以为处理器调度就一定是进程调度，也可能是作业调度

---


##### 4.1.7.2. 先来先服务（FCFS）

![](source/_posts/笔记：操作系统理论/image-20250605181232101.png)

---


##### 4.1.7.3. 短作业优先（SJF）

![](source/_posts/笔记：操作系统理论/image-20250605181346721.png)

---


##### 4.1.7.4. 高相应比优先（HRRN）

![](source/_posts/笔记：操作系统理论/image-20250605181435348.png)
等待时间 = 现在时间 - 到达时间，每次都要重新计算
响应比 = （等待时间 + 服务时间）/服务时间

---


##### 4.1.7.5. 优先级调度（PSA）

![](source/_posts/笔记：操作系统理论/image-20250605181527733.png)

---


##### 4.1.7.6. 时间片轮转调度（RR）

![](source/_posts/笔记：操作系统理论/image-20250605182208816.png)

---


##### 4.1.7.7. 多级反馈队列调度（MFQ）

![](source/_posts/笔记：操作系统理论/image-20250605182525623.png)

---


#### 4.1.8. 处理机的状态

处理机的状态常见有：
1. ==用户态（目态）==：
	1. CPU 只能执行非特权指令
2. 核心态(管态、内核态)：
	1. CPU 可以执行所有指令
3. 用户态 -> 核心态：
	1. 通过中断（硬件完成）
4. 核心态 -> 用户态：
	1. 特权指令 psw 的标志位，0 用户态，1 核心态（仅作了解）

---


#### 4.1.9. 调度的常见算法

1. ==先来先服务（FCFS）==：
	1. 按进入就绪队列的顺序调度，简单但对长作业不利。
2. ==短作业优先（SJF）==：
	1. 优先调度运行时间短的作业，平均等待时间最小，但可能导致长作业“饿死”。
3. ==优先级调度==：
	1. 根据优先级来调度，高优先级先运行，可能饿死低优先级进程。
4. ==高响应比优先（HRN）==：
	1. 综合 FCFS 和 SJF，用响应比 R=等待时间+要求服务时间要求服务时间 R =（等待时间 + 要求服务时间） / 要求服务时间 R=要求服务时间等待时间+要求服务时间​ 来决定调度顺序，既考虑了等待时间又兼顾了作业长短。
5. ==多级反馈队列调度==：
	1. 结合时间片轮转、优先级和反馈机制，是目前最灵活、复杂、也是最常见的一种调度策略。

---


## 5. 存储器管理（内存管理）

### 5.1. 存储器的结构

![](source/_posts/笔记：操作系统理论/image-20250604120028051.png)

---


### 5.2. 进程运行的原理

#### 5.2.1. 程序装入内存过程图示（要转为进程）

![](source/_posts/笔记：操作系统理论/image-20250604123703414.png)

---


#### 5.2.2. 编译阶段

程序的编译，是将源代码转化为机器能够理解或执行的形式。例如：
1. C/C++ 是直接面向底层硬件的语言，其编译产物是机器码，通常为 `.o`、`.obj` 等目标文件；
2. 而 Java 编译的对象是 JVM 虚拟机，因此其编译产物是 `.class` 字节码文件。
在编译过程中，像 Java 这样的语言，通常是一个类或接口就生成一个独立的字节码文件，编译产物较为分散。

> [!NOTE] 注意事项
> 1. 这里的库包括操作系统自带的共享库（如文件库、I/O 库等，均由操作系统提供）、内置库（例如 C 语言自带的标准库）以及第三方依赖库


---



#### 5.2.3. 链接阶段

程序链接主要有三种方式：
1. ==静态链接==：
	1. 发生在程序编译生成可执行文件的时候，编译器会把程序本身需要的所有库函数和模块代码，全部一次性打包进最终的可执行文件里
	2. 程序启动速度快，因为所有代码都已经在一个文件里，运行时不用再去找外部库
	3. 但生成的程序文件体积比较大，而且如果库文件有更新，必须重新编译并链接程序，才能用上新库
2. ==装入时动态链接（装入时链接）==：
	1. 发生在程序装入内存阶段，也就是程序启动时。
	2. 程序代码存于可执行文件中，但库函数代码在程序启动时，由操作系统帮忙加载到内存。
	3. 本质上，在程序启动时，操作系统会把所有依赖的共享库映射进程序的虚拟地址空间（程序的虚拟内存地址空间与库文件在磁盘上的位置进行映射）。调用库函数时，实际上是访问这个虚拟地址，当我们访问这个虚拟地址的时候，操作系统才会把对应的数据从磁盘加载到内存
	4. 多个程序共用同一套共享库时，它们映射到同一份物理内存，库代码只存一份，节省了内存资源，无需为每个程序复制一份库函数
	5. 这样可执行文件体积相对小，因为不包含库代码，而是运行时加载
	6. 如果库更新了，下次启动程序时就自动用到新版本的库，无需重新编译程序
	7. **绑定到共享库中这些函数的地址上**。
3. ==运行时动态链接（运行时链接）==：
    1. 在程序运行过程中，只有当程序真正调用某个库函数时，系统才去加载并链接对应的库。
    2. 这样程序启动更快，内存使用更灵活，未调用的库代码不会被加载。
    3. 表面上与装入时动态链接相似，但装入时动态链接是在程序启动时就映射所有库的地址空间，代码按需加载。
    4. 而运行时动态链接则是“调用时才映射和链接”，库的加载和链接延迟到实际调用时才发生。


![](source/_posts/笔记：操作系统理论/image-20250605231317732.png)
![](source/_posts/笔记：操作系统理论/image-20250605231335064.png)
![](source/_posts/笔记：操作系统理论/image-20250605231518546.png)

---


#### 5.2.4. 装入阶段

程序装入主要有三种方式：
1. ==绝对装入==：
	1. 程序在编译时就确定了它的大小，生成的代码中装入的物理内存地址是固定的。
	2. 通常由程序设计者明确指定装入地址（比如 0~12），程序就按这个地址装入，对程序员要求较高
	3. 装入速度快，运行效率高，但灵活性差。如果内存位置发生变化，比如 0~12 被占用，程序就无法启动
	4. 适合早期的单道处理环境，因为进程数量和内存分配情况明确，程序知道自己可以装入哪个内存区域；但多道处理时，内存分配复杂且动态，难以保证空闲内存位置
2. ==可重定向装入（静态重定位装入）==：
	1. 程序在编译时仍需确定大小，但物理装入地址可以改变，程序通过修正代码中地址引用（重定位）来适应实际分配的内存
	2. 比如程序逻辑地址为 0~12，但是物理内存地址 0~12 被占用，那么可以重定位到空闲的物理内存地址 13~25
	3. 这样程序可以装入不同内存区域，灵活性较绝对装入更高
	4. 适合多道处理的早期阶段，但仍需预先知道程序大小，不适合动态装入
3. ==动态运行时装入（动态重定位装入）==：
	1. 程序运行时不一次性全部加载所有库，而是在需要时动态加载，对应装入时链接和运行时链接机制

----


### 5.3. 内存管理

#### 5.3.1. 内存管理概述

内存管理主要涉及内存的分配，通常包括：
1. 内存的连续分配方式
2. 内存的非连续分配方式
除此之外，我们还会介绍内存扩充的方法，主要针对程序体积较大、内存不足的情况。

----


#### 5.3.2. 内存的连续分配方式

##### 5.3.2.1. 内存的连续分配方式概述

内存的连续分配方式有：
1. 单一连续分配
2. 固定分区分配
3. 动态分区分配

---


##### 5.3.2.2. 单一连续分配

这是最简单的内存分配方式：系统将除系统保留区之外的所有可用内存合并为一个连续的大分区，供单个进程独占使用。换句话说，内存划分为“系统区”和“一个大用户区”，所有用户程序都只能在该用户区内执行。

优点是：
1. 实现简单，管理方便
2. 无需复杂的内存分配算法，只需将整块用户区一次性分配给一个进程，无需再划分多个小块
3. 无外部碎片，不存在外部空闲空间被分割成零散的碎片（因为根本不存在外部空间了）
4. 不一定需要内存保护，因为只有一个用户进程运行，不涉及多个用户进程之间的隔离。但仍需注意系统区与用户区之间的访问安全（所以是不一定需要，而不是一定不需要）

缺点是：
1. 只能同时运行一个程序，存储器利用率低
2. 程序大小受限于整个内存容量，超出部分无法加载（可以使用内存扩充技术）
3. 有内部碎片，程序实际使用的内存往往小于整块分区，导致部分空间浪费
![](source/_posts/笔记：操作系统理论/image-20250606111536575.png)

----


##### 5.3.2.3. 固定分区分配

系统将除系统保留区之外的所有可用内存划分为若干个大小固定的分区，**每个分区独立供一个进程使用**。

分区的大小、起始地址及分配状态由分区说明表记录（该表通常存放于系统区内存中）

优点是：
1. 实现相对简单，管理方便
2. 分区数量和大小固定，不需要动态计算与调整，只需为进程选择合适的空闲分区即可，调度开销也较小
3. 支持同时运行多个进程，相比单一连续分配，可将不同进程分别装入不同分区，提高并发性与利用率。

缺点是：
1. 固定大小分区可能无法适配所有进程需求、
	1. 若进程小于分区容量，则剩余部分无法被其它进程利用，导致空间浪费，内部碎片严重
	2. 若进程大于分区容量，则需要使用内存扩充技术（无法将多个分区合并成大分区）
2. 分区数量固定，扩展性差，如果可用分区都在使用，但有新进程要进入，必须等待或进行重启配置；若分区过剩，则部分分区长期空闲，降低利用率。

![](source/_posts/笔记：操作系统理论/image-20250606111950327.png)

---


##### 5.3.2.4. 动态分区分配

系统将除系统保留区之外的所有可用内存视为一个整体的空闲区域。起初，当进程到来时，系统根据其需求划出相应大小的一块内存，这块区域即视为一个“分区”。该进程退出后，所占用的分区会重新变为新的空闲区。系统通过数据结构（如空闲区链表、空闲区表，该表通常存放于系统区内存中）记录当前所有空闲区的位置和大小。

当新进程请求内存时，系统会优先在现有空闲区中查找合适的连续空间进行分配。例如，若进程需要 6 KB，而找到的空闲区为 8 KB，则系统会从该空闲区划出 6  KB分配给进程，剩余的2KB则被划分为一个新的空闲区。需要注意的是，操作系统通常会设置一个最小分配单位（分配粒度），如果剩余空间小于该单位，则不会再进一步划分，以避免产生过多的碎片。

如果没有直接满足的空闲区，可以尝试将多个相邻的空闲区合并后再判断能否满足需求。如果仍无法满足，系统会从剩余空闲内存中为其划出一个新的分区。随着进程的不断装入与释放，内存中的空闲区数量与分布将动态变化。

优点是：
1. 消除了内部碎片，每次根据进程实际需求划分分区，分配空间更贴合实际，避免了固定分区中 “进程小于分区导致剩余空间浪费”的问题。
2. 内存利用率高，空闲区可动态划分，无需预留固定大小的内存块，显著减少空间浪费。
3. 分配策略灵活多样，通过不同的适应算法（如首次适应、最佳适应等），可以根据实际场景优化分配效率或降低外部碎片产生。
4. 支持多个进程同时运行，相较于单一连续分配，只要存在足够大的空闲区，即可加载相应进程，提高并发能力和内存利用率。

缺点是：
1. 存在外部碎片问题，随着进程频繁申请与释放内存，空闲区被切割成大小不一的碎片（例如：第1区空闲，第2、3区占用，第4区空闲），导致即使总体空闲空间充足，也可能找不到一块足够大的连续区域满足较大进程需求。
2. 分配和回收开销较大，每次分配需遍历空闲区链表寻找合适空间，并可能拆分空闲区；回收时还需检查并合并相邻空闲区，增加了算法复杂度和执行时间。
3. 内存管理复杂，需维护动态变化的空闲区表或链表（或位示图），实时更新状态。相比固定分区，数据结构更复杂，易出错且调试难度较高

![](source/_posts/笔记：操作系统理论/image-20250606132823514.png)

---


#### 5.3.3. 内存的非连续分配

##### 5.3.3.1. 基本分页存储管理

基本分页存储管理和固定分区分配在形式上很相似，都是将内存划分为多个块。但不同的是，分页允许一个进程占用多个非连续的物理块，而固定分区分配中，一个块只能被一个进程占用；分页也不同于动态分区分配，后者要求找到一整块连续的空闲空间，而分页无需考虑物理内存的连续性。

操作系统将逻辑地址空间（即进程所需的虚拟内存空间）划分为若干个大小固定、长度相等的块，称为“页”（Page）；与之对应，物理内存也被划分成同样大小的块，称为“页框”（Frame）。

为了尽量减少内部碎片，每一页的大小通常设计得较小，这一点不同于固定分区分配中分区尺寸较大、容易产生未充分利用的剩余空间。每个进程维护一张页表（该页表保存在 进程PCB 中，由操作系统存放于系统内存区），用于记录逻辑页与物理页框之间的映射关系。

![](source/_posts/笔记：操作系统理论/image-20250606135102882.png)

---


##### 5.3.3.2. 基本分段存储管理

一个应用，每个模块可能占用的内存不一样，如果我们像上面一样全部列出来，其实是不太好管理的
![](source/_posts/笔记：操作系统理论/image-20250606140124152.png)

----


##### 5.3.3.3. 段页式管理方式

先分段再分页，一个进程一个段表，一个段表项一个页表，一个页表多个物理块

![](source/_posts/笔记：操作系统理论/image-20250606140256568.png)

----


#### 5.3.4. 内存的扩充

内存扩充的常见手段有：
1. ==覆盖==：
	1. 当内存仅有 1G，而程序需占用 2G 时，无法一次性装入全部内容。此时可让常用的常驻内存，不常用的在需要时覆盖式加载
2. ==交换==：
	1. 当内存空间紧张时，可以将部分内存中的进程暂时换出到外存（挂起），再将外存中已准备好运行的进程换入内存。
3. ==虚拟内存==：
	1. 详见下文 “虚拟内存管理” 部分

----


### 5.4. 虚拟内存管理


















---


## 6. 文件管理

### 6.1. 文件概述

文件是信息在计算机系统中的基本存储单位，通常以计算机硬盘等存储介质为载体，用于组织和管理数据。它是用户与操作系统交互、存储数据和程序的主要方式。

---

### 6.2. 文件的属性

文件具有一组用于描述其状态和管理信息的属性，包括但不限于：文件名、文件类型、文件大小、存储位置、访问权限等等
![](source/_posts/笔记：操作系统理论/image-20250604145748064.png)

---


### 6.3. 文件的操作

操作系统为用户和程序提供了多种文件操作接口，主要包括：创建文件、打开与关闭文件、读写文件、文件定位（寻址）、删除文件、截断文件

---


### 6.4. 文件的结构

#### 6.4.1. 文件的逻辑结构

##### 6.4.1.1. 文件的逻辑结构概述

文件的逻辑结构是从用户和程序员的角度来看，文件内部数据的组织方式，而不涉及它在磁盘上的物理排布。

----


##### 6.4.1.2. 无结构文件（流式文件）

无结构文件指的是文件**内部的数据没有固定的组织结构**，系统将其中的数据按字节（Byte）为单位、顺序排列进行存储。操作系统并不会对这些字节的内容做出任何解释或假设，具体的含义和格式完全依赖于应用程序根据需求进行解析。

举个例子，像我们日常使用的 `.txt` 文本文件、`.java` 源代码文件，它们在逻辑上就是典型的无结构文件。我们可以在文件的任意位置自由地插入数据、添加注释或修改内容，不受字段格式、记录长度等结构约束——想写哪里就写哪里，非常灵活。

也正因为它“无结构”，它的操作非常灵活、简单，尤其适合顺序访问。但与此同时也存在缺点：由于缺乏内部组织，若我们希望定位某一特定数据（比如某一行、某个关键字），就只能通过穷举扫描（如全文搜索）的方式查找。这种方式在小文件中影响不大，但在处理大规模数据或频繁查找时，效率就会显得不足。
![](source/_posts/笔记：操作系统理论/image-20250604170710743.png)

> [!NOTE] 注意事项
> 1. 无论是无结构文件（如 `.txt`、`.java`、`.jpg` 等），还是有结构文件（如 `.csv`、`.ibd` 等），对操作系统来说，本质上都是普通的字节序列文件。操作系统并不关心文件内容是中文、Java 代码，还是 Markdown，或者是否有特定结构。
> 	1. 以 `.txt` 文件为例，当我们使用 Notepad++ 保存文件时，Notepad++ 会根据选定的字符编码方式（例如 UTF-8，不同编码方式会将字符转换为不同的二进制码）将文本内容转换成对应的二进制字节序列（1 字节 = 8 位二进制，8 bit）。这个编码过程完全由应用程序内部完成。
> 	2. 随后，操作系统接收这些二进制字节序列，通过文件系统（如 NTFS、ext4 等）将它们写入硬盘的具体位置。操作系统负责管理磁盘空间分配、缓存处理以及更新文件的元数据（例如文件大小、修改时间等）。
> 	3. 当 Notepad++ 需要读取该文件时，操作系统从磁盘加载相应的二进制字节序列到内存，并通过系统提供的接口供程序访问。Notepad++ 再按照其内部逻辑将这些字节解析并显示为可读的文字内容。
> 2. 也就是说，操作系统的职责仅是接收并存储二进制字节序列，使其成为硬盘上的文件，或将文件内容加载到内存供程序使用。那么，为什么还要区分无结构文件和有结构文件呢？
> 	1. 这其实是从程序设计角度出发的分类
> 	2. 对于无结构文件，程序若要定位某部分内容，只能通过逐字节或全文扫描的方式进行查找，效率较低
> 	3. 而对于有结构文件（例如每条记录固定为 256 字节），程序可以根据记录大小计算出某条记录在文件中的具体字节偏移，从而快速定位到目标记录，无需进行全文扫描，访问效率大大提高

---


##### 6.4.1.3. 有结构文件（记录式文件）

###### 6.4.1.3.1. 有结构文件概述

这类文件由若干条结构化记录组成，每条记录可以是固定长度或变长的。其优点是结构明确，便于快速定位和访问特定记录；缺点是灵活性较差，不适合存储复杂多样的数据格式。

例如，CSV 文件中每一行代表一条记录，字段之间用逗号分隔，应用程序通常按记录单位进行处理：
```
id,name,score
101,Anna,88
102,Bob,92
```

再如日志文件，每条日志也是一条记录，由固定格式的字段组成：
```
2025-06-04 14:30:22 | user: alice | action: login
2025-06-04 14:35:00 | user: bob | action: logout
```

有结构文件大致分为：
1. 顺序文件
2. 索引文件
3. 索引顺序文件
4. 直接文件（散列文件、Hash 文件）

----


###### 6.4.1.3.2. 顺序文件

顺序文件又可分为变长顺序文件和定长顺序文件：
1. ==变长顺序文件==：
	1. 每条记录的长度不固定，例如 `.csv` 文件，字段之间用逗号分隔，不同记录的长度可能不同，程序通常逐行读取并解析。
2. ==定长顺序文件==：
	1. 每条记录长度相同，便于通过字节偏移直接定位记录，例如数据库的 `.ibd` 文件，虽然实际插入的数据可能大小不一，但我们都申请了固定空间（如 `VARCHAR(20)` ），整体上形成了定长的存储布局。
![](source/_posts/笔记：操作系统理论/image-20250604182339375.png)

---


###### 6.4.1.3.3. 索引文件

文件中建立了独立索引结构（如索引表或索引块，索引与数据分离），不仅可以通过 “关键字 → 字节偏移” 的方式快速定位记录，还可以实现变长，如我们 MySQL 的 `.MYI` 文件
![](source/_posts/笔记：操作系统理论/image-20250604182536954.png)

---


###### 6.4.1.3.4. 索引顺序文件

索引顺序文件是顺序文件 + 索引结构的结合，既可以按顺序遍历，也可以按索引跳转定位。
![](source/_posts/笔记：操作系统理论/image-20250604190000531.png)

当数据量非常大时，一个单层索引表所能覆盖的记录数量是有限的。为了解决这个问题，我们可以采用多级索引结构：在原有索引表之上再建立更高一层的索引，用于索引“索引表”。
![](source/_posts/笔记：操作系统理论/image-20250604190222746.png)

> [!NOTE] 注意事项
> 1. 例如，若每个索引项占 16 字节，常见的页大小为 4KB（即 4096 字节），则一个索引页最多可容纳 `4096 ÷ 16 = 256` 个索引项。
> 2. 当数据记录数量远超单页索引容量时，就需要在索引项之上再构建一层索引，形成多级索引结构。

---


###### 6.4.1.3.5. 直接文件（散列文件、Hash 文件）

用哈希函数将关键字直接映射到物理地址或记录的偏移位置，实现近似 O(1) 的随机访问，例如 Redis 的 `.rdb` 文件
![](source/_posts/笔记：操作系统理论/image-20250604190620867.png)

---


##### 6.4.1.4. 文件的目录结构

###### 6.4.1.4.1. 文件的目录结构概述

文件的目录结构是指操作系统或文件系统用来组织和管理文件层级关系的方式。常见的目录结构有：
1. 单级目录结构
2. 二级目录结构
3. 树形目录结构
4. 无环图（DAG）目录结构

而在实现这些结构时，文件系统内部还需要维护每个文件的元数据信息，常用的数据结构包括：
1. 文件控制块（FCB）
2. 索引节点（inode）

> [!NOTE] 注意事项
> 1. FCB 和 inode 不是同一个东西，它们都是用于管理文件的元数据结构，但属于不同的文件系统设计方式。

---

###### 6.4.1.4.2. 文件控制块（FCB）

FCB 应用于 传统操作系统（如早期 DOS、Windows），是操作系统内部用来管理文件的重要数据结构，包含了文件的各种关键信息，例如：
1. 文件名和扩展名
2. 文件属性（只读、隐藏、系统文件等）
3. 文件大小
4. 文件的物理存储位置（如磁盘上的起始地址或索引）
5. 文件创建时间、修改时间、访问时间
6. 文件打开状态、访问权限
7. 关联的缓冲区指针或文件句柄

操作系统通过 FCB 来跟踪和管理文件的元数据，方便文件的打开、读取、写入和关闭等操作，我们资源管理器展示的，其实就是从 FCB 或 inode 等结构中拿出来展现给我们的。
![](source/_posts/笔记：操作系统理论/image-20250605115823481.png)

---


###### 6.4.1.4.3. 索引节点（inode）

inode 应用于类 Unix 系统（如 Linux、FreeBSD 等），索引节点不包含文件名，而是包含文件属性、文件大小等信息，我们通过文件名对应的索引节点指针来定位本文件具体的索引节点。

![](source/_posts/笔记：操作系统理论/image-20250605115933479.png)

---


### 6.5. 文件的控制方式

![](source/_posts/笔记：操作系统理论/image-20250605121338563.png)

---


### 6.6. 文件的实现

#### 6.6.1. 文件的实现概述

文件的实现分为两部分：
1. 文件分配方式
2. 文件存储空间管理

---


#### 6.6.2. 文件分配方式

##### 6.6.2.1. 文件分配方式概述

文件分配方式就是讲文件数据在物理磁盘上是如何分配的，主要有以下几种方式：
1. 连接分配
2. 链接分配
3. 索引分配



好的，我来给你分别讲讲这三种文件分配方式：

1. **连接分配**  
    连接分配也称为**连续分配**，是指文件在磁盘上占用的一段连续的物理空间。换句话说，文件的数据块在磁盘上是连在一起的，形成一个连续的区域。  
    **优点**：访问速度快，因为数据连续，读取时可以顺序访问，减少寻道时间。  
    **缺点**：容易产生“磁盘碎片”，难以找到一块足够大的连续空间来存放文件，尤其是文件动态增长时。
    
2. **链接分配**  
    链接分配是将文件分成若干个不连续的块，每个块除了存储数据外，还包含一个指针，指向下一个块的位置。文件以链表的形式存储。  
    **优点**：解决了连续分配中空间不足的问题，能够灵活利用磁盘空间。  
    **缺点**：访问文件时必须顺序遍历链表，随机访问效率低，而且指针占用一定的存储空间。
    
3. **索引分配**  
    索引分配通过一个索引块来管理文件所有的数据块地址。索引块中存放所有数据块的指针，文件系统通过这个索引块可以直接定位文件的任意块。  
    **优点**：支持随机访问，文件块不必连续，且管理较为集中。  
    **缺点**：索引块本身也需要占用空间，且当文件非常大时，单个索引块可能无法容纳所有指针，需要多级索引。
    

这三种方式各有优缺点，实际应用中往往根据需求进行选择或结合使用。你觉得哪部分想更深入了解？


适合随机访问的是 **索引分配**。

因为索引分配通过一个专门的索引块直接存储文件所有数据块的地址，可以快速定位任意数据块，实现高效的随机访问。相比之下，连接分配只能顺序访问连续块，链接分配需要顺着链表逐块查找，随机访问效率较低。


1. **连续分配（Contiguous Allocation）也支持随机访问**
    
    - 在连续分配方式下，文件的所有逻辑块在物理介质（磁盘或存储设备）上是成组地、紧邻地存放的。
        
    - 操作系统只要知道该文件的起始物理块号（即基址），就可以根据要访问的逻辑块号直接计算出对应的物理块号：
        
        复制编辑
        
        `物理块号 = 起始块号 + （要访问的逻辑块号）`
        
    - 由于不需要像链式分配那样逐块跳转，而是通过简单的加法运算直接定位，因而随机访问（访问任意一个逻辑块）非常高效。访问开销仅是一次寻址和一次读写操作，与索引分配的思想相似——都是通过“已知位置 + 偏移”的方式直接跳转。
        
2. **索引分配（Indexed Allocation）当然也支持随机访问**
    
    - 索引分配会为每个文件分配一个专门的索引块（或索引表）。索引块内部存储了该文件中所有逻辑块对应的物理块号。
        
    - 当要访问某个逻辑块时，系统首先读取一次索引块，查看该逻辑块的物理地址，然后再直接定位到对应的物理块进行读写。
        
    - 由于索引块是驻留在内存或缓冲区中（且一般会有缓存机制），读取一次索引块的开销相对可控，后续的随机定位也是一次直接定位。因此，索引分配同样能够在 O(1)O(1)O(1) 时间左右完成任意块的访问。
        
3. **为什么链接分配（Linked Allocation）不适合随机访问？**
    
    - 链接分配中，每个逻辑块都在自身的链表指针里存储下一个块的物理地址。要跳到文件的第 N 个块，必须从头块开始，沿着这些指针一个一个地追下去，直到第 N 个节点才能定位到目标物理块。
        
    - 这种方式在顺序读取（从头到尾、依次读块）时非常简单，但一旦需要随机访问第 N 块，就需要遍历 N−1 次指针，效率会随着块数线性增长，因而不适合随机访问。
        

---

**小结：**

- **连续分配**：通过“起始地址 + 偏移”即可直接定位到任意块，支持高效随机访问。
    
- **索引分配**：先从索引块获取目标块的物理地址，再直接定位，也支持高效随机访问。
    
- **链接分配**：必须沿着指针链依次跳转，随机访问时开销非常大，不适合。
    

因此，正确答案应当是选项 **D（连续分配 和 索引分配）**。

---


##### 6.6.2.2. 连接分配

我们的磁盘通常也会进行分区（如划分为若干扇区），现在一般一个扇区的大小是 4K，文件保存到磁盘上，其实就是保存在这些 4K 大小的扇区中。

所谓连续分配，就是指文件的数据被顺序地存放在一组相邻的扇区中。

优点：
1. 支持顺序访问和直接访问
2. 访问速度快，操作简单

缺点：
1. 不方便扩展
2. 会产生磁盘碎片
![](source/_posts/笔记：操作系统理论/image-20250605235308568.png)

> [!NOTE] 注意事项
> 1. 连续分配类似数组，天然支持随机访问（随机访问和直接访问都指能快速定位并读取文件中任意位置的数据，不用从头或顺序读到目标位置，你可以把他们看作同义词）

---


##### 6.6.2.3. 链接分配

![](source/_posts/笔记：操作系统理论/image-20250605122755944.png)

---

	
##### 6.6.2.4. 索引分配

![](source/_posts/笔记：操作系统理论/image-20250605123055738.png)

如果我们的文件特别大，可以：
![](source/_posts/笔记：操作系统理论/image-20250605123223431.png)

---




#### 6.6.3. 文件存储空间管理

##### 6.6.3.1. 文件存储空间管理概述

就是讲文件存储空间是如何进行管理的，主要有以下几种方式：
1. 空闲表法
2. 空闲链表法
3. 成组链接法
4. 位示图法 

---


##### 6.6.3.2. 空闲表法

![](source/_posts/笔记：操作系统理论/image-20250605123504580.png)

---


##### 6.6.3.3. 空闲链表法

![](source/_posts/笔记：操作系统理论/image-20250605123524314.png)

---


##### 6.6.3.4. 位示图法

![](source/_posts/笔记：操作系统理论/image-20250605123707615.png)

---



















## 7. 设备管理

### 7.1. I/O 概述

I/O（Input/Output）指的是输入与输出操作，即将数据从外部设备输入到计算机（CPU），或将计算机（CPU）处理后的数据输出到外部设备。

---


### 7.2. I/O 设备的分类

1. ==按使用特性分类==：
	1. 人机交互类外部设备：
		1. 用于人与计算机之间的信息交互。
		2. 如 鼠标、键盘、触控板、显示器等。
	2. 存储设备：
		1. 用于长期或中期保存数据。
		2. 如 硬盘、固态硬盘、U 盘等；
	3. 网络通信：
		1. 用于计算机之间或计算机与其他系统之间的数据通信。
		2. 如 网卡、Wi-Fi 模块、蓝牙模块等
2. ==按数据传输速率分类==：
	1. 低速设备：
		1. 如 键盘、鼠标等
	2. 中速设备：
		1. 如 传统硬盘、USB 接口设备等
	3. 高速设备：
		1. 如 固态硬盘、网卡（如千兆网卡）、高带宽的图像采集设备等
3. ==按信息交换单位分类==：
	1. 块设备：
		1. 数据以固定大小的块为单位进行读写，适合随机访问
		2. 如 硬盘、SSD 等
	2. 字符设备
		1. 数据按字节或字符流方式传输，适合顺序访问。
		2. 如 串口、键盘、鼠标等

> [!NOTE] 注意事项
> 1. 字符本质上是字节的组合单位，一个字符可能由一个或多个字节组成，具体取决于所使用的字符编码。
> 	1. 例如，在 UTF-8 编码中，英文字母通常占一个字节，而汉字可能占三个字节
> 2. 需要注意，我们在此处探讨的是 **I/O 设备的类型划分**，而非 I/O 操作本身，事实上，大多数 I/O 操作都建立在具体 I/O 设备的支持之上
> 	1. 比如网络通信操作，本质上依赖通信设备（如网卡）完成数据的发送与接收
> 	2. 又如文件系统中的读写行为，依托的是存储设备（如磁盘）的读写能力

---


### 7.3. I/O 设备的构成

#### 7.3.1. I/O 设备的构成概述

I/O 设备通常由两部分构成：机械部件 和 电子部件
1. ==机器部件==：
	1. 指设备中可供用户直接操作或感知的物理结构，这部分用于执行具体的 I/O 动作，是人与设备交互的接口
	2. 如 键盘的按键、鼠标的按钮、打印机的喷头等。
2. ==电子部件（I/O控制器、设备控制器）==：
	1. 是连接 CPU、I/O 设备与其他硬件之间的中介桥梁

---


#### 7.3.2. I/O 控制器

##### 7.3.2.1. I/O 控制器概述

I/O 控制器是连接 CPU、I/O 设备与其他硬件之间的中介桥梁，其主要功能包括：
1. ==接收并识别 CPU 命令==：
		1. 接收并识别来自 CPU 的 I/O 命令，转化为 I/O 设备能够理解和执行的控制信号
2. ==向 CPU 报告 I/O 设备的状态==
3. ==数据交换==：
		1. 从 I/O 设备中读取数据发送给 CPU，或将来自 CPU 的数据写入 I/O 设备
4. ==地址识别==：
	1. 根据 CPU 发送的地址信息判断出具体要操作的是哪一个 I/O 设备或设备内部的哪个寄存器

----


##### 7.3.2.2. I/O 控制器的组成

![](source/_posts/笔记：操作系统理论/image-20250605105809959.png)

---


### 7.4. I/O 控制方式

#### 7.4.1. I/O 控制方式概述

I/O 控制方式是指 I/O 操作的完成方式，涉及 CPU、I/O 控制器以及 I/O 设备。主要包括以下几种方式：
1. 程序直接控制方式
2. 中断驱动方式
3. DMA 方式（直接内存访问）
4. 通道控制方式

---


#### 7.4.2. 程序直接控制方式

##### 7.4.2.1. 程序直接控制方式概述

程序直接控制方式是指由 CPU 主动、反复轮询 I/O 控制器的状态寄存器，每次仅完成 一个字（word）大小的数据的读或写操作

> [!NOTE] 注意事项
> 1. 一个“字”的位数依赖于具体机器字长，例如在 32 位系统中，一个字通常是 32 位（4 字节）

---


##### 7.4.2.2. 程序直接控制方式图示

![](source/_posts/笔记：操作系统理论/image-20250605111034701.png)

---


##### 7.4.2.3. 读操作流程

1. CPU 向控制器的控制寄存器写入“读请求”命令，同时通过地址线传送目标设备的端口地址
2. 控制器接收到命令后，启动设备内部的数据准备流程，并将状态寄存器设置为“busy”状态
3. CPU 通过不断轮询控制器的状态寄存器，持续检查设备是否进入“ready”状态，即数据是否准备就绪
4. 一旦设备准备好数据，控制器将数据写入数据寄存器，并将状态寄存器更新为“ready”状态
5. 此时，CPU 监测到状态改变，即可通过读取数据寄存器将数据取出
6. 传输后，设备会清空或重置状态寄存器，表示本次传输完成；
7. 如果需读取多个字节，则从步骤 2 开始重复整个流程，直到传输结束

---


##### 7.4.2.4. 写操作流程

1. CPU 向控制器的 控制寄存器 写入“写请求”命令，同时通过 地址线 传送目标设备的端口地址
2. 控制器接收到命令后，准备接受来自 CPU 的数据，并将 状态寄存器 设置为 “busy” 状态
3. CPU 通过不断轮询控制器的 状态寄存器，持续检查设备是否进入 “ready” 状态，即是否可以发送数据
4. 一旦设备准备好接收，CPU 将数据写入控制器的 数据寄存器，控制器随后把数据发送给目标设备
5. 数据发送完成后，控制器将 状态寄存器 重置或更新，以表示本次传输结束；
6. 若还有多个数据字节需要写入，则 CPU 将从步骤 2 开始重复整个流程，直到所有数据传输完成

---


#### 7.4.3. 中断驱动方式

##### 7.4.3.1. 中断驱动方式概述

中断驱动方式与程序直接控制方式的不同在于：当控制器接收到命令后，会向 CPU 发送一次中断请求信号，此时 CPU 将暂停当前任务，转而处理 I/O 请求。  而在数据准备或接收完成后，控制器 **再次向 CPU 发送中断信号**，通知其进行一次读或写操作。  这种方式避免了 CPU 持续轮询状态寄存器，从而显著提升了处理效率。
> [!NOTE] 注意事项
> 1. 中断方式下，每次中断仍然只处理一个字（word）大小的数据
> 2. 由于一次只处理一个字，数据量实际上并不大。说实话，如果中断频率过高，会对效率造成较大影响，但总体上仍然优于程序直接控制方式。

![](source/_posts/笔记：操作系统理论/image-20250605113423128.png)

----


#### 7.4.4. DMA 方式（直接内存访问）

![](source/_posts/笔记：操作系统理论/image-20250605113731012.png)

----


#### 7.4.5. 通道控制方式

![](source/_posts/笔记：操作系统理论/image-20250605114030512.png)

---

















