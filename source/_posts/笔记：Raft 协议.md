---
title: 笔记：Raft 协议
date: 2025-05-12
categories:
  - Java
  - 分布式与微服务
  - 分布式一致性协议
  - Raft 协议
tags: 
author: 霸天
layout: post
---
### 1. Raft 协议概述

Raft 是一种 分布式一致性协议中的强一致性的协议，用于在多台服务器（或节点）之间 保持数据一致性，即便有部分节点发生故障。它的出现是为了解决一个经典的问题：“我们有多个节点，如果有一个客户端对系统发起写入请求，我们怎么保证这些节点最终看到的是同一份数据？怎么能保证即使部分节点宕机，整个集群依然能保持数据一致、服务不中断。”

---


### 2. Raft 协议三个核心角色

1. ==Follower==：
	1. 安静等待 Leader 的指令
2. ==Candidate==：
	1. 视图成为 Leader 的节点
3. ==Leader==：
	1. 负责管理整个集群、处理客户端请求并同步日志

---


### Raft 协议核心特性

1. ==多数投票选 Leader==：
    1. 启动时，所有节点默认处于 Follower 状态。
    2. 若某个 Follower 在选举超时时间内未收到 Leader 的心跳信号，则会升级为 Candidate 并主动发起投票。
    3. 一旦某个 Candidate 获得超过半数（即 > N/2）的节点投票，即可当选为 Leader。这种机制有效防止了脑裂问题。（为避免平票，建议集群中参与选举的节点数为奇数）
    4. 其他节点一旦接收到新 Leader 的心跳信号，便自动“认输”，继续担任 Follower。
2. ==强一致日志复制==：
    1. Leader 接收到客户端请求后，会先将日志条目同步给所有 Follower。只有在多数节点（超过半数）确认写入后，日志才视为“提交成功”。
    2. 一旦日志被提交，你可以确信：即使当前 Leader 崩溃，新选出的 Leader（同样来自多数派）也一定持有这条日志。
    3. 不必担心“落后节点”当选 Leader。在投票前，节点会先检查候选人的日志是否至少和自己一样新，才会投票。这就杜绝了日志落后的节点“混进多数”并被选为 Leader 的可能性。
    4. 至于那些日志未及时同步的节点，也无需担心：即使它们宕机或网络波动，恢复后也会自动检测日志落后，并向当前 Leader 请求补齐。
    5. 而我们的读和写都是由 Leader 进行完成，这样就保证了强一致性，但这也带来了 Leader 压力和性能瓶颈问题。感觉如果用什么措施缓解，就不是强一直性了
3. ==明确的 Term（任期）概念==：
    1. 每一轮选举都有一个全局递增的 `term`，可以理解为 “现在掌权的是第几届村长”。该 term 保存在每个节点中，谁的 term 高，谁就拥有更高优先级，从而防止 “过时村长” 重新掌权。
4. ==自动故障转移==：
    1. 如果 Leader 崩溃，Follower 会因为收不到心跳而自动发起新一轮选举。新 Leader 会基于现有日志无缝接管，集群能够自动恢复并继续提供服务。

---


![](image-20250615095342892.png)




### 深入理解 Term 的概念

1. ==初始状态==：
    1. 假设集群中有 5 个具备选举资格的节点（A、B、C、D、E），要成为 Leader 需要获得多数票（≥3 票）。
    2. 此时 A 是当前的 Leader（term=10），定期向 B、C、D、E 发送心跳信号。
2. ==Leader A 宕机==：
    1. A 宕机后，B、C、D、E 都不再收到心跳信号，触发各自的选举超时定时器（150–300 ms 随机）。
    2. <font color="#00b0f0">假如 B 最先超时未收到心跳</font>：
        1. B 超时在先（如 180 ms），检测到未收到心跳，便将 `term` 从 10 增加到 11，变为 Candidate。B 立即给自己投票（票数=1），并向 C、D、E 以及已掉线的 A 广播 `RequestVote(term=11, candidateId=B, lastLog…)`。
        2. C、D、E 收到 B 的请求后，发现请求中的 term=11 比自己当前的 term=10 更新，便更新 term → 11，切回 Follower 身份，检查 B 的日志无落后后，投票给 B。
        3. B 收到来自 C 和 D 的投票（B 自己 + C + D = 3 票），满足多数要求，成功当选为新 Leader（term=11）。
        4. B 立即向其他活跃节点（C、D、E）以及离线的 A 发送心跳 `AppendEntries(term=11)`。C、D、E 收到后重置选举定时器，保持 Follower 状态；
        5. 如果 A 之后恢复上线，它将收到 B 的心跳 RPC，并发现 term=11 比自己的 term=10 更新，于是更新自己的 term → 11，退回 Follower 状态，放弃原先的 Leader 身份。这样保证：一个处于旧 term 的节点无法参与当前任期的投票或发起选举，只有“意识到要进入新一届”的节点才能重新参选。
    3. <font color="#00b0f0">假如 B、C 几乎同时超时未收到心跳</font>：
        1. 若 B 和 C 的选举超时非常接近（如均为 180 ms 左右），两者几乎同时将 term 从 10 升为 11，变为 Candidate，并向其余节点广播 `RequestVote(term=11)`（B 向 A、C、D、E 发，C 向 A、B、D、E 发）。
        2. 假设 D 先收到 B 的请求，检查通过后将票投给 B，并更新 term → 11。
        3. 同时，E 先收到 C 的请求，也检查通过并投票给 C，更新 term → 11。
        4. 当 B 收到来自 C 的 `RequestVote(term=11)` 请求时，B 发现自己在当前 term（11）中已将票投给自己，因此拒绝给 C 投票。C 也是同理（只能投一次，投给自己就没办法投给别人了）
        5. B 最终得票为自己 + D = 2，C 得票为自己 + E = 2，均未获得多数 → **选票分裂（split vote）**，本轮选举失败。
        6. B、C、D、E 的选举超时器重新启动，等待下一轮触发。再次进入超时的节点将把 term 增加到 12 并发起新一轮选举，如此循环，直到有人获得多数票成功当选。term 会随着失败轮次不断累加。
3. ==A 节点重连==：
    1. A 节点重启后，term 仍是 10。当它收到新 Leader（如 D）发来的心跳 `AppendEntries(term=11)` 后，立刻发现对方的 term 更新，于是更新自己的 term → 11，退回 Follower 身份，开始正常接受日志同步，重新与集群保持一致。
        
---


![](image-20250615124445749.png)